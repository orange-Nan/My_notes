逻辑回归Logistic Regression

属性：分类模型，常用于二分类

原理：假设数据服从这个分布，然后使用极大似然估计做参数的估计。

例子：以二分类为例，对于所给数据集假设存在这样的一条直线可以将数据完成线性可分。
逻辑回归的思路是，先拟合决策边界（不局限于线性，还可以是多项式），再建立这个边界与分类的概率联系，从而得到了二分类情况下的概率。
逻辑回归模型的数学形式确定后，剩下就是如何去求解模型中的参数。在统计学中，常常使用极大似然估计法来求解，即找到一组参数，使得在
这组参数下，我们的数据的似然度（概率）最大。

常用求解方法：随机梯度下降、牛顿法、正则化
（1）随机梯度下降：通过 J(w) 对 w 的一阶导数来找下降方向，并且以迭代的方式来更新参数
（2）牛顿法：在现有极小点估计值的附近对 f(x) 做二阶泰勒展开，进而找到极小点的下一个估计值
（3）正则化：所有会产生过拟合现象的算法都可以使用正则化来避免过拟合。
在经验风险最小化的基础上（也就是训练误差最小化），尽可能采用简单的模型，可以有效提高泛化预测精度。如果模型过于复杂，变量值稍微
有点变动，就会引起预测精度问题。正则化之所以有效，就是因为其降低了特征的权重，使得模型更为简单。

优点：（1）直接对分类的概率建模，无需实现假设数据分布，从而避免了假设分布不准确带来的问题（区别于生成式模型）；
（2）不仅可预测出类别，还能得到该预测的概率，这对一些利用概率辅助决策的任务很有用；
（3）对数几率函数是任意阶可导的凸函数，有许多数值优化算法都可以求出最优解。
