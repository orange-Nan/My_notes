支持向量机Support Vector Machines（SVR/SVM）

1.属性：
支持向量机是一种有监督学习算法（分类或回归）。

2.原理
SVM学习的基本想法是求解（找出一个函数）正确划分训练数据集并且几何间隔最大的分离超平面。
对于线性可分的数据集来说，这样的超平面有无穷多个（即感知机），但是几何间隔最大的分离超平面却是唯一的。
它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机。SVM的学习策略就是间隔最大化，可形式化为一个求解凸二次规
划的问题，也等价于正则化的合页损失函数的最小化问题。SVM的的学习算法就是求解凸二次规划的最优化算法。
SVM还包括核技巧，这使它成为实质上的非线性分类器。SVM利用内积核函数代替向高维空间的非线性映射，从而达到在统计样本量较少的情况下，亦能获得
良好统计规律的目的。
*线性可区分和线性不可区分:
能够用一条直线对样本点进行分类的属于线性可区分（linear separable），否则为线性不可区分（linear inseparable)

3.思路：

4.常用求解方法：
常用的核函数：
h度多项式核函数(polynomial kernel of degree h)
高斯径向基核函数(Gaussian radial basis function kernel)
S型核函数(Sigmoid function kernel)

5.优点：
（小样本）SVM可以在较少的数据下取得好的性能
（性能）泛化性能比较好, 不容易过拟合
缺点：
（不适用于大量数据）大规模训练样本（m阶矩阵计算） 速度慢
（缺失值）对缺失值敏感
（多分类）不太适用于多分类问题
（参数复杂）参数设置较为复杂

6.与其他模型对比
