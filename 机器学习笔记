一、机器学习概述
1.机器学习发展历程：
20世纪70-80年代 知识工程、专家系统 → 机器学习
2.常见名词包含关系：
深度学习∈神经网络∈机器学习∈人工智能（AI）
3.机器学习的五大学派
（1）符号学派
关键词：逆向演绎、准确度、逻辑
（2）联结学派
关键词：梯度下降、平方误差、神经网络
（3）类推学派
关键词：约束优化、边际、支持向量
（4）贝叶斯学派
关键词：概率推理、后验概率、图解模型
（5）进化学派
关键词：遗传搜索、适应度、遗传程序
4.机器学习过程：
具体事物数据 → 机器学习模型 → 模型预测/分类结果
  机器学习模型的步骤：模型初步选择→模型参数调优（调参）→模型性能评估，其核心部分为模型调参及选择
5.机器学习类型
（1）有监督学习
任务：学习数据中的模式，适用于预测新数据
理解：之所以叫作有监督学习，是因为算法模型基于样本数据的预测结果，都有一个真实结果用于比较，从而帮助操作者改善算法模型
典型算法：主要包括回归和分类两大类
  逻辑回归、决策树、支持向量机、随机森林、朴素贝叶斯、神经网络等
练习例子：【练习1】鸢尾花数据集
（2）无监督学习
任务：寻找数据中蕴含的模式
典型算法：主要包括聚类和降维两大类
  K均值聚类（Kmeans）、主成分分析（PCA）等
练习例子：【练习2】极端气温识别
6.机器学习的任务：分类、回归、聚类、降维
（1）分类（预测一个数值）
输出类型：离散数据
目的：寻找决策边界
评价方法：精度(accuracy)、混淆矩阵等
常见算法：
  KNN算法（K-近邻）：使用距离测量的方法进行分类
  决策树（DecisionTree）：通过选区最优特征划分数据集，构建一棵树，表示我们的整个决策过程
  朴素贝叶斯（NaiveBayes）：基于概率论的分类方法，贝叶斯公式
  逻辑回归（LogisticRegression）：回归（拟合）+Sigmoid函数
  *注意：逻辑回归(logistic)是一种分类算法，其输出的结果是不连续的决策边界
（2）回归（预测一个类别）
*分类和回归的区别：是否存在“阈值判断”
输出类型：连续数据
目的：找到最优拟合
评价方法：SSM(sum of square errors)或拟合优度
回归算法：
  线性回归（LinearRegression，回归）：不同情况下可以使用不同的回归方法，一般先采用线性回归方法得到最佳拟合直线。
    当出现欠拟合时，可采用局部加权线性回归；如果样本特征比样本数还多，就考虑使用缩减方法岭回归、lasso和前向逐步回归。
  树回归：是决策树的一种。包括分类回归数（CART算法，Classification And Regression Tree）、随机森林（RF）、梯度提升树（GBM）等
  岭回归（Ridge）：解决普通最小二乘法的一些问题，例如当特征之间完全共线性(有解)或者说特征之间高度相关，这个时候适合用岭回归
  Lasso回归：是一个估计稀疏系数的线性模型。由于它倾向于选择参数值较少的解，有效地减少了给定解所依赖的变量的数量
  支持向量机（SVR/SVM）：可以用于分类或回归，根据输入的数据不同可做不同的模型（若输入标签为连续值则做回归，若输入标签为分类值则做分类）
（3）聚类（一系列点分成若干类）
输出类型：离散数据
目的：将一系列点分成若干类（具体的类别是未知的）
常见算法：
  K-Means聚类：把所有数据点划分到K个互斥组别里。复杂之处在于如何选取K的大小。
  层次聚类 (Hierarchical Clustering) ：把所有数据点划分到一些组别、和它们的子组别里，形成像族谱一样的树状图。
    比如，先把用户按年龄分组，然后把各个组别按照其他标准再细分。
  概率聚类 (Probabilistic Clustering) ：把所有数据点按照概率来分组。K-Means其实就是它的一种特殊形式，即概率永远为0或1的情况。
*聚类和分类的区别：
  分类的目的是为了确定一个点的类别，具体有哪些类别是已知的，常用的算法是KNN算法，是一种有监督学习。
  聚类的目的是将一系列点分成若干类，事先是没有类别的，常用的算法是K-Means算法，是一种无监督学习。
  两者也有共同点：对于想要分析的目标点，都会在数据集中寻找离它最近的点，即二者都用到了 NN (Nears Neighbor) 算法。
（4）降维（数据集压缩）
常见算法：
  主成分分析算法 (PCA) ：找出能够把数据集里的大多数变化联系起来的线性组合。
  奇异值分解 (SVD) ：把数据的矩阵分解成三个小矩阵。
7.机器学习的主要步骤（需要工程师操作的部分）：
特征提取 → 特征处理（特征预处理） → 特征选择
  *降维算法也可以用于特征预处理

二、常见名词解释
1.特征矩阵(X1,×2,..,X3)
  行:样本/向量  列:特征
2.分类算法中:X特征向量 Y标签值
3.数据集dataset:
一些名词：
  样本sample：每一条单独的数据
  属性attribute/特征feature：对于每个样本，它都具有一些特征
  特征值feature value：特征所具体取的值
  特征空间feature space/样本空间sample space：特征和样本所张成的向量空间
在有监督学习中数据集dataset可分为以下几个部分：
  训练集Training Set：用来训练我们模型的部分
  测试集Test Set：用来测试、评估模型泛化能力的部分
  交叉验证集Cross-Validation Set，CV Set：这是比较特殊的一部分数据，它是用来调整模型具体参数的
4.常见错误：
  （1）没有为模型准备足够的数据
  如果你的数据集很小，模型就无法获得足够的用于泛化的辨别特征。这样模型就会过拟合数据，造成训练错误很低但测试错误很高的问题。
  解决方案：1）收集更多数据 2）数据增强
  （2）数据类的质量很低
  解决方法：为你的数据类选择正确的粒度级别
